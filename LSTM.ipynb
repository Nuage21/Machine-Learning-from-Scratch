{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dinosaur Names Generator with RNNs \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's import the libraries we'll use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aachenosaurus\n",
      "aardonyx\n",
      "abelisaurus\n",
      "abrictosaurus\n",
      "abrosaurus\n",
      "abydosaurus\n",
      "acantholipan\n",
      "acanthopholis\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dino_file = open('datasets/dino.txt', 'r')\n",
    "dinos = dino_file.read()\n",
    "dino_file.close()\n",
    "print(dinos[:99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abrictosaurus', 'abrosaurus', 'abydosaurus']\n",
      "The dataset contains 1533 exemples\n"
     ]
    }
   ],
   "source": [
    "dino_list = dinos.split('\\n')\n",
    "print(dino_list[3:6])\n",
    "print(f'The dataset contains {len(dino_list)} exemples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's see all the chars that figure in the names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'c', 'h', 'e', 'n', 'o', 's', 'u', 'r', 'd', 'y', 'x', 'b', 'l', 'i', 't', 'p', 'v', 'm', 'k', 'g', 'f', 'j', 'w', 'z', 'q', '_']\n"
     ]
    }
   ],
   "source": [
    "all_chars = []\n",
    "for dino in dino_list:\n",
    "    splitted = list(dino)\n",
    "    for c in splitted:\n",
    "        if c not in all_chars:\n",
    "            all_chars.append(c)\n",
    "print(all_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in addition to alphabet chars, the underscore '_' does also figure in and should be counted later, next we'll append each training sample with a start and end character padding to a maximum length:\n",
    "But before let's see the longest dinosaur name in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longest name contains 23 characters\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "for dino in dino_list:\n",
    "    lng = len(dino)\n",
    "    if lng > max_len:\n",
    "        max_len = lng\n",
    "print(f'longest name contains {max_len} characters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's pad the names and add the start/end chars:\n",
    "But first let's create a simple padding function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dino$$$'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def padname(name, pad_char, maxl):\n",
    "    to_add = maxl - len(name)\n",
    "    if to_add <= 0:\n",
    "        return name\n",
    "    to_append = ''.join([pad_char] * to_add)\n",
    "    return name + to_append\n",
    "\n",
    "padname('Dino', '$', 7) # exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['~aachenosaurus$$$$$$$$$$$', '~aardonyx$$$$$$$$$$$$$$$$', '~abelisaurus$$$$$$$$$$$$$', '~abrictosaurus$$$$$$$$$$$', '~abrosaurus$$$$$$$$$$$$$$']\n"
     ]
    }
   ],
   "source": [
    "start_char = '~'\n",
    "end_char = '$'\n",
    "dino_list = [start_char + padname(dino_name.lower(), end_char, max_len) + end_char for dino_name in dino_list]\n",
    "print(dino_list[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll split dino names into charcaters to form our dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['~', 'a', 'a', 'c', 'h', 'e', 'n', 'o', 's', 'a', 'u', 'r', 'u', 's', '$', '$', '$', '$', '$', '$', '$', '$', '$', '$', '$']\n",
      "['a', 'a', 'c', 'h', 'e', 'n', 'o', 's', 'a', 'u', 'r', 'u', 's', '$', '$', '$', '$', '$', '$', '$', '$', '$', '$', '$', '$']\n"
     ]
    }
   ],
   "source": [
    "dataset_X = [list(dino) for dino in dino_list]\n",
    "dataset_y = []\n",
    "for l in dataset_X:\n",
    "    y_label = l[1:] + [end_char]\n",
    "    dataset_y.append(y_label)\n",
    "    \n",
    "print(dataset_X[0]) # first sample\n",
    "print(dataset_y[0]) # first label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll feed the RNN with one-hot representation of characters and to do so, we'll need to create a dictionnary mapping each char in the dataset to an integer which will be converted to a one hot later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25, '~': 26, '$': 27, '_': 28}\n"
     ]
    }
   ],
   "source": [
    "char_to_int = {chr(x): x - ord('a') for x in range(ord('a'), ord('z') + 1)}\n",
    "char_to_int[start_char] = 26\n",
    "char_to_int[end_char] = 27\n",
    "char_to_int['_'] = 28\n",
    "print(char_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get the inverted dictionnay:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'a', 1: 'b', 2: 'c', 3: 'd', 4: 'e', 5: 'f', 6: 'g', 7: 'h', 8: 'i', 9: 'j', 10: 'k', 11: 'l', 12: 'm', 13: 'n', 14: 'o', 15: 'p', 16: 'q', 17: 'r', 18: 's', 19: 't', 20: 'u', 21: 'v', 22: 'w', 23: 'x', 24: 'y', 25: 'z', 26: '~', 27: '$', 28: '_'}\n"
     ]
    }
   ],
   "source": [
    "int_to_char = {v: k for k, v in char_to_int.items()}\n",
    "print(int_to_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the dictionary above, we can now implement a fucntion that returns the one-hot vector of a character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "-------------------------------\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "def one_hot(c):\n",
    "    order = char_to_int[c]\n",
    "    return keras.utils.to_categorical(order, num_classes = len(char_to_int))\n",
    "\n",
    "def one_hot_list(l): # ret: numpy array\n",
    "    ret = []\n",
    "    for c in l:\n",
    "        ret.append(one_hot(c))\n",
    "    return np.array(ret)\n",
    "\n",
    "print(one_hot('f'))\n",
    "print('-------------------------------')\n",
    "print(one_hot_list(['a', 'b', 'c']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence length = 25\n",
      "Number of samples = 1533\n",
      "Input vector shape = (29,)\n",
      "--\n",
      "X shape is (1533, 25, 29)\n",
      "y shape is (1533, 25, 29)\n"
     ]
    }
   ],
   "source": [
    "Tx = len(dino_list[0])\n",
    "n_samples = len(dino_list)\n",
    "input_vec_shape = (len(one_hot('a')), )\n",
    "\n",
    "print(f'Sequence length = {Tx}')\n",
    "print(f'Number of samples = {n_samples}')\n",
    "print(f'Input vector shape = {input_vec_shape}')\n",
    "\n",
    "\n",
    "X, y = np.zeros((n_samples, Tx, input_vec_shape[0])), np.zeros((n_samples, Tx, input_vec_shape[0]))\n",
    "\n",
    "for i in range(n_samples):\n",
    "    X_hot = one_hot_list(dataset_X[i])\n",
    "    y_hot = one_hot_list(dataset_y[i])\n",
    "    X[i, :, :] = X_hot\n",
    "    y[i, :, :] = y_hot\n",
    "    \n",
    "print('--')\n",
    "print(f'X shape is {X.shape}')\n",
    "print(f'y shape is {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our dataset is preprocessed, let's create our model and compile it:\n",
    "### Model and Training\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, None, 120)         72000     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, None, 64)          7744      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, None, 29)          1885      \n",
      "=================================================================\n",
      "Total params: 81,629\n",
      "Trainable params: 81,629\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=[None, 29]),\n",
    "    keras.layers.LSTM(120, return_sequences = True),\n",
    "    keras.layers.Dense(64, activation = 'relu'),\n",
    "    keras.layers.Dense(29, activation = 'softmax'),\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8669 - acc: 0.5271\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8884 - acc: 0.5271\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8790 - acc: 0.5271\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8451 - acc: 0.5271\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7957 - acc: 0.5271\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7410 - acc: 0.5271\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6907 - acc: 0.5271\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6519 - acc: 0.5274\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6284 - acc: 0.5274\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6213 - acc: 0.5280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0ac44894f0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, batch_size = n_samples, epochs=10, verbose = 1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more conveniance, let's save the model so we can load it (with the weights) whenever we want: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/RNN.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Loading & Prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 9ms/step - loss: 0.3204 - acc: 0.8916\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3204 - acc: 0.8916\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3761 - acc: 0.8765\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3297 - acc: 0.8899\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3485 - acc: 0.8837\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3471 - acc: 0.8845\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.3362 - acc: 0.8884\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('./models/RNN.h5')\n",
    "ex_loss, ex_acc = model.evaluate(X, y)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "model.fit(X, y, batch_size = n_samples, epochs=5, verbose = 1, shuffle=False)\n",
    "\n",
    "now_loss, now_acc = model.evaluate(X, y)\n",
    "if now_loss < ex_loss:\n",
    "    model.save('RNN.h5')\n",
    "    print('model saved !')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll define a function to retrieve the string form of the predicted sequence from its one-hot representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "string prediction = anraenosaurus$$$$$$$$$$$$\n"
     ]
    }
   ],
   "source": [
    "def get_str_pred(pred): # pred shape sould be (1x..x1) x 29\n",
    "    pred = pred.reshape(-1, 29)\n",
    "    str_pred = []\n",
    "    for c in pred:\n",
    "#         int_c = np.random.choice(29, p = c)\n",
    "        int_c = np.argmax(c)\n",
    "        \n",
    "        real_c = int_to_char[int_c]\n",
    "        str_pred.append(real_c)\n",
    "    \n",
    "    return ''.join(str_pred)\n",
    "\n",
    "x = np.array([X[0, :, :]])\n",
    "str_pred = get_str_pred(model.predict(x))\n",
    "print(f'string prediction = {str_pred}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can implement a generator function that takes a sequence beginning as argument and complete it by recursively predicting the next character and let's try it over some funny names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACRONOSAURUS\n",
      "--\n",
      "TRUDAUDIN\n",
      "--\n",
      "TREVORHON\n",
      "--\n",
      "GRUSJITASAUR\n"
     ]
    }
   ],
   "source": [
    "def generate_after(seq_beg):\n",
    "    seq_hot = np.array(one_hot_list(list(seq_beg))).reshape(1, -1, 29)\n",
    "    pred = model.predict(seq_hot)[0, -1, :].argmax()\n",
    "    pred = int_to_char[pred]\n",
    "    if pred != '$':\n",
    "        return generate_after(seq_beg + pred)\n",
    "    return seq_beg[1:] # remove the start token\n",
    "\n",
    "# Let's try some fun names\n",
    "\n",
    "print(generate_after('~macron').upper()) # Emanuel Macron \n",
    "print('--')\n",
    "print(generate_after('~trudau').upper()) # Justin Trudeau\n",
    "print('--')\n",
    "print(generate_after('~trevor').upper()) # Trevor (Noah)\n",
    "print('--')\n",
    "print(generate_after('~gru').upper()) # GRU (Gated Recurrent Unit xD)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
