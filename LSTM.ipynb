{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dinosaur Names Generator with RNNs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's import the libraries we'll use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aachenosaurus\n",
      "aardonyx\n",
      "abelisaurus\n",
      "abrictosaurus\n",
      "abrosaurus\n",
      "abydosaurus\n",
      "acantholipan\n",
      "acanthopholis\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dino_file = open('datasets/dino.txt', 'r')\n",
    "dinos = dino_file.read()\n",
    "dino_file.close()\n",
    "print(dinos[:99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abrictosaurus', 'abrosaurus', 'abydosaurus']\n",
      "The dataset contains 1533 exemples\n"
     ]
    }
   ],
   "source": [
    "dino_list = dinos.split('\\n')\n",
    "print(dino_list[3:6])\n",
    "print(f'The dataset contains {len(dino_list)} exemples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's see all the chars that figures in the names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'c', 'h', 'e', 'n', 'o', 's', 'u', 'r', 'd', 'y', 'x', 'b', 'l', 'i', 't', 'p', 'v', 'm', 'k', 'g', 'f', 'j', 'w', 'z', 'q', '_']\n"
     ]
    }
   ],
   "source": [
    "all_chars = []\n",
    "for dino in dino_list:\n",
    "    splitted = list(dino)\n",
    "    for c in splitted:\n",
    "        if c not in all_chars:\n",
    "            all_chars.append(c)\n",
    "print(all_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in addition to alphabet chars, the underscore '_' does also figure in and should be counted later, next we'll append each training sample with a start and end character padding to a maximum length:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's see the longest dinosaur name in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longest name contains 23 characters\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "for dino in dino_list:\n",
    "    lng = len(dino)\n",
    "    if lng > max_len:\n",
    "        max_len = lng\n",
    "print(f'longest name contains {max_len} characters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's pad the names and add the start/end chars:\n",
    "But first let's create a simple padding function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dino$$$'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def padname(name, pad_char, maxl):\n",
    "    to_add = maxl - len(name)\n",
    "    if to_add <= 0:\n",
    "        return name\n",
    "    to_append = ''.join([pad_char] * to_add)\n",
    "    return name + to_append\n",
    "\n",
    "padname('Dino', '$', 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['~aachenosaurus$$$$$$$$$$$', '~aardonyx$$$$$$$$$$$$$$$$', '~abelisaurus$$$$$$$$$$$$$', '~abrictosaurus$$$$$$$$$$$', '~abrosaurus$$$$$$$$$$$$$$']\n"
     ]
    }
   ],
   "source": [
    "start_char = '~'\n",
    "end_char = '$'\n",
    "dino_list = [start_char + padname(dino_name.lower(), end_char, max_len) + end_char for dino_name in dino_list]\n",
    "print(dino_list[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll split dino names into charcaters to form our dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['~', 'a', 'a', 'c', 'h', 'e', 'n', 'o', 's', 'a', 'u', 'r', 'u', 's', '$', '$', '$', '$', '$', '$', '$', '$', '$', '$', '$']\n",
      "['a', 'a', 'c', 'h', 'e', 'n', 'o', 's', 'a', 'u', 'r', 'u', 's', '$', '$', '$', '$', '$', '$', '$', '$', '$', '$', '$', '$']\n"
     ]
    }
   ],
   "source": [
    "dataset_X = [list(dino) for dino in dino_list]\n",
    "dataset_y = []\n",
    "for l in dataset_X:\n",
    "    y_label = l[1:] + [end_char]\n",
    "    dataset_y.append(y_label)\n",
    "    \n",
    "print(dataset_X[0]) # first sample\n",
    "print(dataset_y[0]) # first label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll feed the RNN with one-hot representation of characters and to do so, we'll need to create a dictionnary mapping each char in the dataset to an integer which will be converted to a one hot later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25, '~': 26, '$': 27, '_': 28}\n"
     ]
    }
   ],
   "source": [
    "char_to_int = {chr(x): x - ord('a') for x in range(ord('a'), ord('z') + 1)}\n",
    "char_to_int[start_char] = 26\n",
    "char_to_int[end_char] = 27\n",
    "char_to_int['_'] = 28\n",
    "print(char_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get the inverted dictionnay:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'a', 1: 'b', 2: 'c', 3: 'd', 4: 'e', 5: 'f', 6: 'g', 7: 'h', 8: 'i', 9: 'j', 10: 'k', 11: 'l', 12: 'm', 13: 'n', 14: 'o', 15: 'p', 16: 'q', 17: 'r', 18: 's', 19: 't', 20: 'u', 21: 'v', 22: 'w', 23: 'x', 24: 'y', 25: 'z', 26: '~', 27: '$', 28: '_'}\n"
     ]
    }
   ],
   "source": [
    "int_to_char = {v: k for k, v in char_to_int.items()}\n",
    "print(int_to_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the dictionary above, we can now implement a fucntion that returns the one-hot vector of a character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "-------------------------------\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "def one_hot(c):\n",
    "    order = char_to_int[c]\n",
    "    return keras.utils.to_categorical(order, num_classes = len(char_to_int))\n",
    "\n",
    "def one_hot_list(l): # ret: numpy array\n",
    "    ret = []\n",
    "    for c in l:\n",
    "        ret.append(one_hot(c))\n",
    "    return np.array(ret)\n",
    "\n",
    "print(one_hot('f'))\n",
    "print('-------------------------------')\n",
    "print(one_hot_list(['a', 'b', 'c']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAXLENGTH = 25\n",
      "Number of samples = 1533\n",
      "Input vector shape = (29,)\n",
      "data shape is (1533, 25, 29)\n",
      "exemple: \n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "Tx = len(dino_list[0])\n",
    "n_samples = len(dino_list)\n",
    "input_vec_shape = (len(one_hot('a')), )\n",
    "\n",
    "print(f'MAXLENGTH = {Tx}')\n",
    "print(f'Number of samples = {n_samples}')\n",
    "print(f'Input vector shape = {input_vec_shape}')\n",
    "\n",
    "\n",
    "X, y = np.zeros((n_samples, Tx, input_vec_shape[0])), np.zeros((n_samples, Tx, input_vec_shape[0]))\n",
    "\n",
    "for i in range(n_samples):\n",
    "    X_hot = one_hot_list(dataset_X[i])\n",
    "    y_hot = one_hot_list(dataset_y[i])\n",
    "    X[i, :, :] = X_hot\n",
    "    y[i, :, :] = X_hot\n",
    "    \n",
    "print(f'data shape is {data.shape}')\n",
    "print('exemple: ')\n",
    "print(X[0, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our dataset is preprocessed, let's create our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_4 (SimpleRNN)     (None, 25, 32)            1984      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 25, 29)            957       \n",
      "=================================================================\n",
      "Total params: 2,941\n",
      "Trainable params: 2,941\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(25, 29)),\n",
    "    keras.layers.SimpleRNN(32, return_sequences = True),\n",
    "    keras.layers.Dense(29, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4405 - acc: 0.9632\n",
      "Epoch 2/12\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2970 - acc: 0.9788\n",
      "Epoch 3/12\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.1998 - acc: 0.9873\n",
      "Epoch 4/12\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.1371 - acc: 0.9938\n",
      "Epoch 5/12\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.0960 - acc: 0.9968\n",
      "Epoch 6/12\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.0688 - acc: 0.9990\n",
      "Epoch 7/12\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.0504 - acc: 0.9994\n",
      "Epoch 8/12\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.0379 - acc: 0.9996\n",
      "Epoch 9/12\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.0292 - acc: 0.9998\n",
      "Epoch 10/12\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.0231 - acc: 0.9998\n",
      "Epoch 11/12\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.0185 - acc: 0.9999\n",
      "Epoch 12/12\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.0152 - acc: 0.9999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2d51ebb700>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "model.fit(X, y, epochs=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 29)\n",
      "(25, 29)\n"
     ]
    }
   ],
   "source": [
    "print(X[0, :, :].shape)\n",
    "pred = model.predict(np.array([X[0, :, :]]))[0]\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~aachenosaurus$$$$$$$$$$$\n"
     ]
    }
   ],
   "source": [
    "str_pred = []\n",
    "for c in pred:\n",
    "    int_c = np.argmax(c)\n",
    "    real_c = int_to_char[int_c]\n",
    "    str_pred.append(real_c)\n",
    "    \n",
    "str_pred = ''.join(str_pred)\n",
    "\n",
    "print(str_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
